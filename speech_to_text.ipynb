{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAwArxnnsuokXZHs17TaJ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NgPcAnhh/study/blob/main/speech_to_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgczLTOEgCBm",
        "outputId": "2fbba121-cf3a-4c5a-91d5-61388d9b596e",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/800.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/800.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2.0.0->openai-whisper) (3.17.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803373 sha256=55f59bb58ceaa17d07868d99a0a5f32b9a70ad299c9747ee0a7456a5e631b5e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGOABUH3ja4z",
        "outputId": "8c9561bf-250b-4d23-c5f2-5b1eeb7b81bd",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-ib7_pd3c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-ib7_pd3c\n",
            "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803669 sha256=1de86d8cc3e3b3c4dd194ec5c29bd81de020036ee5d1ff6bd1f5f6ada4788840\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p302mrpu/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: openai-whisper\n",
            "  Attempting uninstall: openai-whisper\n",
            "    Found existing installation: openai-whisper 20240930\n",
            "    Uninstalling openai-whisper-20240930:\n",
            "      Successfully uninstalled openai-whisper-20240930\n",
            "Successfully installed openai-whisper-20240930\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    # Load model - chọn 'base' cho tốc độ nhanh và nhẹ\n",
        "    model = whisper.load_model(\"base\")\n",
        "\n",
        "    # Chuyển đổi audio thành text\n",
        "    result = model.transcribe(audio_path, fp16=False)\n",
        "\n",
        "    return result[\"text\"]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_audio = \"webtest_VSR.wav\"  # Thay đổi đường dẫn file tại đây\n",
        "    transcription = transcribe_audio(input_audio)\n",
        "    print(\"Transcription result:\")\n",
        "    print(transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRWHDjGJcDXb",
        "outputId": "d412ef65-1e4c-4e4b-b104-d527722bc3ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription result:\n",
            " This is the simulator speaking test and I'm your examiner. Can you hear my voice? Okay, please make sure your microphone is on and your RR is silent. You should adjust the volume before the test. Are you ready? Let's start. Now, in this first part, I'd like to ask you some questions about yourself. What kind of work do you do? Right now, I'm the software engineer specializing in web application. My job involves coding, debugging, and collaborating with the teams to build a efficient and usefully friendly platform. Do you work best in the morning or the afternoon? Why? I am more productive in the morning because my mind is fresh and I can focus better. Also, the quiet environment in the early hour allow me to complete complex task efficiently. Incredible. Which do you use more often pen or pencil? I use a pen more frequently because it provides smoother writing experience and it's more suitable for the official documents. However, I also use pencil when sketching or taking route note. Fantastic. When was the last time you bought a pen or pencil? I bought a pen last week because my old one ran out of ink and I prefer gel pens as the grind smoothly and last longer. Do you often use your mobile phone for texting or making phone calls? I mostly use my mobile phone for texting because it is more convenient and allows me to communicate with the disrupting other. However, for Asian matter, I prefer making a phone call. That's wonderful to hear. Do you remember your first mobile phone? Yes, I do. It was a basic Nokia model with the monochrome screens and it didn't have many features but it was durable and had a long battery life. Do you like swimming? Yes, I love swimming. It is a great way to stay fit and relax especially on the hot summer day. Why do many people like swimming? Many people enjoy swimming because it's a low impact exercise that works as whole bodies and it also refresh a way to unwind and relieve stress. Interesting. Do you watch science programs on TV? Yes, I occasionally watch science documentaries on channels like National Geographic or Discoveries. I try to provide fascinating insight into space technologies and also the natural. Fantastic. Is it easy for you to learn science subjects? I find science subjects quite challenging for me but I enjoy them because they explain how the world works and understanding the concept requires logical thinking and practice. That is the end of part 1. Now let's move on to part 2. In part 2, I'm going to give you a topic and I'd like you to talk about it for 1 to 2 minutes. Before you talk, you'll have 1 minute to think about what you are going to say. You can make notes if you wish. Describe a group or a club you have ever joined. Alright, remember you have 1 to 2 minutes for this. I will tell you when the time is up. Start speaking now. One of the most memorable clubs I have ever joined was my university's debate club. I became a member in my second year of university because I wanted to improve my public speaking and critical thinking skills. The club was well organized with weekly meetings, held a large lecture halls on campus. Each section was attained by students from different faculties which made discussion even more engaging and diverse. When I first joined, I was quite nervous because I had a little experience in form rebate. However, the senior members were very supportive and guided new members through the process. Every week we would be assigned different topics ranging from social issue and politics to science and ethics. We had to research the topics, prepare arguments and then participate in structural debate when we took to presenting our viewpoint. One of the most exciting experiences I had in my club was participating in inter-university debate competitions. It was challenging yet rewarding experience because I had to compete against teams from other universities. I spent our practicings with my teammates, refining my arguments and learning how to respond to the counter-agumings. Effectively, although my team did not win the competitions, I also gained valuable skill in logical reasonings, persuasive speaking and teamwork. That's the end of part 2. Now let's move on to part 3. You've been talking about a topic and I'd like to discuss with you some general questions related to it. Impressive. Are there any downsides to being part of a group or club? Yes, sometimes being in groups can be time consuming and require commitment. Conflicts may also arise due to the difference in opinions and personal lies. How important are extracurricular activities for students? Extracurricular activities are essential for students. As they helped develop soft skills, foster teamwork and provide a break from academic stress. Wonderful. What are the benefits of joining a group or club? Joining a group helps people build social connection, improve communication skills, and gain new knowledge or experience in structure and environment. How have online groups and communities changed social interactions? An online group have made social interaction more accessible and inclusive, allowing people to connect globally. However, they sometimes reduce face-to-face communications, leading to weaker real-world social skills. That is the end of the speaking test. Thank you for your time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = transcription\n",
        "\n",
        "emotion = [\n",
        "    \"So\", \"Sounds great\", \"Ok\", \"Awesome\", \"Your idea is good\", \"Good\",\n",
        "    \"Interesting\", \"Impressive\", \"That's wonderful to hear!\", \"Fascinating\",\n",
        "    \"Wow!\", \"Amazing!\", \"Incredible!\", \"Fantastic!\", \"Wonderful!\", \"Excellent!\",\n",
        "    \"Nice!\", \"Brilliant!\", \"Outstanding!\", \"Great!\", \" \", \" \", \" \", \" \", \" \", \" \", \" \", \" \", \" \",\n",
        "];\n",
        "\n",
        "conversation = []\n",
        "conversation.append(\"\\n--- Part 1 ---\\n\")\n",
        "\n",
        "\n",
        "# First clean up the text by removing unnecessary characters\n",
        "text = text.replace('\"\"\"', '').strip()\n",
        "text = text.replace('\\n', ' ').strip()\n",
        "text = text.replace(')', '').strip()\n",
        "\n",
        "# Get the part 1 section\n",
        "intro_mark = text.find(\"Now, in this first part, I'd like to ask you some questions about yourself\")\n",
        "ending_part1_mark = text.find(\"That is the end of part 1\")\n",
        "filter_text = text[intro_mark:ending_part1_mark]\n",
        "\n",
        "# Split text into sentences more accurately\n",
        "sentences = []\n",
        "current_sentence = \"\"\n",
        "for char in filter_text:\n",
        "    current_sentence += char\n",
        "    if char in ['?', '.']:\n",
        "        sentences.append(current_sentence.strip())\n",
        "        current_sentence = \"\"\n",
        "\n",
        "i = 0\n",
        "\n",
        "while i < len(sentences):\n",
        "    sentence = sentences[i].strip()\n",
        "\n",
        "    # Skip empty sentences\n",
        "    if not sentence:\n",
        "        i += 1\n",
        "        continue\n",
        "\n",
        "    # Handle questions\n",
        "    if '?' in sentence:\n",
        "        # Check for emotion words at the start\n",
        "        clean_sentence = sentence\n",
        "        for em in emotion:\n",
        "            if clean_sentence.lower().startswith(em.lower()):\n",
        "                clean_sentence = clean_sentence[len(em):].strip()\n",
        "                break\n",
        "\n",
        "        conversation.append(f\"examiner: {clean_sentence}\")\n",
        "\n",
        "        # Collect all answers until next question\n",
        "        answer_parts = []\n",
        "        j = i + 1\n",
        "        while j < len(sentences) and '?' not in sentences[j]:\n",
        "            answer_sentence = sentences[j].strip()\n",
        "            if answer_sentence:\n",
        "                # Clean emotion words from answer parts\n",
        "                for em in emotion:\n",
        "                    if answer_sentence.lower().startswith(em.lower()):\n",
        "                        answer_sentence = answer_sentence[len(em):].strip()\n",
        "                        break\n",
        "                if answer_sentence:\n",
        "                    answer_parts.append(answer_sentence)\n",
        "            j += 1\n",
        "\n",
        "        if answer_parts:\n",
        "            conversation.append(f\"candidate: {' '.join(answer_parts)}\")\n",
        "        i = j - 1  # Set i to the last processed sentence\n",
        "\n",
        "    i += 1\n",
        "\n",
        "# Add delimiter for part 2\n",
        "conversation.append(\"\\n--- Part 2 ---\\n\")\n",
        "\n",
        "intro_part2_mark = text.find(\"You can make notes if you wish\")\n",
        "part2_question = text[intro_part2_mark:].split('.')[1].strip()\n",
        "# gán câu hỏi vào\n",
        "conversation.append(f\"examiner: {part2_question}\")\n",
        "\n",
        "part2_speaking_marking = text.find(\"Start speaking now.\")\n",
        "part2_finished_marking = text.find(\"That's the end of part 2.\")\n",
        "\n",
        "for line in text[part2_speaking_marking + len(\"Start speaking now.\"):part2_finished_marking].split('\\n'):\n",
        "    if line:\n",
        "        conversation.append(f\"candidate: {line}\")\n",
        "\n",
        "# Add delimiter for part 3\n",
        "conversation.append(\"\\n--- Part 3 ---\\n\")\n",
        "\n",
        "# First process part 3 introduction and first question\n",
        "part3_question_start = text.find(\"Now let's move on to part 3\")\n",
        "part3_question_end = text.find(\"You've been talking about a topic\", part3_question_start)\n",
        "part3_intro = text[part3_question_start:part3_question_end].strip()\n",
        "\n",
        "# Process remaining questions and answers\n",
        "remaining_text_start = text.find(\"You've been talking about a topic\")\n",
        "remaining_text_end = text.find(\"That is the end of the speaking test\")\n",
        "remaining_text = text[remaining_text_start:remaining_text_end]\n",
        "\n",
        "# Split text into sentences more accurately\n",
        "sentences_part3 = []\n",
        "current_sentence = \"\"\n",
        "for char in remaining_text:\n",
        "    current_sentence += char\n",
        "    if char in ['?', '.']:\n",
        "        sentences_part3.append(current_sentence.strip())\n",
        "        current_sentence = \"\"\n",
        "\n",
        "conversation_part3 = []\n",
        "i = 0\n",
        "\n",
        "while i < len(sentences_part3):\n",
        "    sentence = sentences_part3[i].strip()\n",
        "\n",
        "    # Skip empty sentences\n",
        "    if not sentence:\n",
        "        i += 1\n",
        "        continue\n",
        "\n",
        "    # Handle questions\n",
        "    if '?' in sentence:\n",
        "        # Check for emotion words at the start\n",
        "        clean_sentence = sentence\n",
        "        for em in emotion:\n",
        "            if clean_sentence.lower().startswith(em.lower()):\n",
        "                clean_sentence = clean_sentence[len(em):].strip()\n",
        "                break\n",
        "\n",
        "        conversation_part3.append(f\"examiner: {clean_sentence}\")\n",
        "\n",
        "        # Collect all answers until next question\n",
        "        answer_parts = []\n",
        "        j = i + 1\n",
        "        while j < len(sentences_part3) and '?' not in sentences_part3[j]:\n",
        "            answer_sentence = sentences_part3[j].strip()\n",
        "            if answer_sentence:\n",
        "                # Clean emotion words from answer parts\n",
        "                for em in emotion:\n",
        "                    if answer_sentence.lower().startswith(em.lower()):\n",
        "                        answer_sentence = answer_sentence[len(em):].strip()\n",
        "                        break\n",
        "                if answer_sentence:\n",
        "                    answer_parts.append(answer_sentence)\n",
        "            j += 1\n",
        "\n",
        "        if answer_parts:\n",
        "            conversation_part3.append(f\"candidate: {' '.join(answer_parts)}\")\n",
        "        i = j - 1  # Set i to the last processed sentence\n",
        "\n",
        "    i += 1\n",
        "\n",
        "# Append combined conversation including intro and remaining part to conversation\n",
        "conversation.append(f\"examiner: {part3_intro}\")\n",
        "for line in conversation_part3:\n",
        "    conversation.append(line)\n",
        "\n",
        "# Print the conversation\n",
        "for i in conversation:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq6Dr3ACf8zQ",
        "outputId": "da42ce62-a955-401c-ded8-1e289f47c10b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Part 1 ---\n",
            "\n",
            "examiner: What kind of work do you do?\n",
            "candidate: Right now, I'm the software engineer specializing in web application. My job involves coding, debugging, and collaborating with the teams to build a efficient and usefully friendly platform.\n",
            "examiner: Do you work best in the morning or the afternoon?\n",
            "examiner: Why?\n",
            "candidate: I am more productive in the morning because my mind is fresh and I can focus better. Also, the quiet environment in the early hour allow me to complete complex task efficiently. Incredible.\n",
            "examiner: Which do you use more often pen or pencil?\n",
            "candidate: I use a pen more frequently because it provides smoother writing experience and it's more suitable for the official documents. However, I also use pencil when sketching or taking route note. Fantastic.\n",
            "examiner: When was the last time you bought a pen or pencil?\n",
            "candidate: I bought a pen last week because my old one ran out of ink and I prefer gel pens as the grind smoothly and last longer.\n",
            "examiner: Do you often use your mobile phone for texting or making phone calls?\n",
            "candidate: I mostly use my mobile phone for texting because it is more convenient and allows me to communicate with the disrupting other. However, for Asian matter, I prefer making a phone call. That's wonderful to hear.\n",
            "examiner: Do you remember your first mobile phone?\n",
            "candidate: Yes, I do. It was a basic Nokia model with the monochrome screens and it didn't have many features but it was durable and had a long battery life.\n",
            "examiner: Do you like swimming?\n",
            "candidate: Yes, I love swimming. It is a great way to stay fit and relax especially on the hot summer day.\n",
            "examiner: Why do many people like swimming?\n",
            "candidate: Many people enjoy swimming because it's a low impact exercise that works as whole bodies and it also refresh a way to unwind and relieve stress. .\n",
            "examiner: Do you watch science programs on TV?\n",
            "candidate: Yes, I occasionally watch science documentaries on channels like National Geographic or Discoveries. I try to provide fascinating insight into space technologies and also the natural. Fantastic.\n",
            "examiner: Is it easy for you to learn science subjects?\n",
            "candidate: I find science subjects quite challenging for me but I enjoy them because they explain how the world works and understanding the concept requires logical thinking and practice.\n",
            "\n",
            "--- Part 2 ---\n",
            "\n",
            "examiner: Describe a group or a club you have ever joined\n",
            "candidate:  One of the most memorable clubs I have ever joined was my university's debate club. I became a member in my second year of university because I wanted to improve my public speaking and critical thinking skills. The club was well organized with weekly meetings, held a large lecture halls on campus. Each section was attained by students from different faculties which made discussion even more engaging and diverse. When I first joined, I was quite nervous because I had a little experience in form rebate. However, the senior members were very supportive and guided new members through the process. Every week we would be assigned different topics ranging from social issue and politics to science and ethics. We had to research the topics, prepare arguments and then participate in structural debate when we took to presenting our viewpoint. One of the most exciting experiences I had in my club was participating in inter-university debate competitions. It was challenging yet rewarding experience because I had to compete against teams from other universities. I spent our practicings with my teammates, refining my arguments and learning how to respond to the counter-agumings. Effectively, although my team did not win the competitions, I also gained valuable skill in logical reasonings, persuasive speaking and teamwork. \n",
            "\n",
            "--- Part 3 ---\n",
            "\n",
            "examiner: Now let's move on to part 3.\n",
            "examiner: Are there any downsides to being part of a group or club?\n",
            "candidate: Yes, sometimes being in groups can be time consuming and require commitment. Conflicts may also arise due to the difference in opinions and personal lies.\n",
            "examiner: How important are extracurricular activities for students?\n",
            "candidate: Extracurricular activities are essential for students. As they helped develop soft skills, foster teamwork and provide a break from academic stress. Wonderful.\n",
            "examiner: What are the benefits of joining a group or club?\n",
            "candidate: Joining a group helps people build social connection, improve communication skills, and gain new knowledge or experience in structure and environment.\n",
            "examiner: How have online groups and communities changed social interactions?\n",
            "candidate: An online group have made social interaction more accessible and inclusive, allowing people to connect globally. However, they sometimes reduce face-to-face communications, leading to weaker real-world social skills.\n"
          ]
        }
      ]
    }
  ]
}